Generating Text Using LSTM
Introduction:
In this project I have create a generative model for text, character-by-character using LSTM recurrent neural networks in Python with Keras. Recurrent neural networks can also be used as generative models. LSTM recurrent neural networks can be slow to train and it is highly recommend that you train them on GPU hardware. The dependencies between characters and the conditional probabilities of characters in sequences so that we can in turn generate wholly new and original sequences of characters. These project is not limited to text, you can also experiment with other ASCII data, such as computer source code, marked up documents in LaTeX, HTML or Markdown and more.
Description:
	The book, which used as the dataset is wonderland.txt (https://www.gutenberg.org/files/11/11-0.txt). We need to load the ASCII text for the book into memory and convert all of the characters to lowercase to reduce the vocabulary that the network must learn. The book has just under 150,000 characters and that when converted to lowercase that there are only 47 distinct characters in the vocabulary for the network to learn. Much more than the 26 in the alphabet. I split the book text up into subsequences with a fixed length of 100 characters, an arbitrary length, just as easily split the data up by sentences and pad the shorter sequences and truncate the longer ones. Each training pattern of the network is comprised of 100 time steps of one character (X) followed by one character output (y). When creating these sequences, we slide this window along the whole book one character at a time, allowing each character a chance to be learned from the 100 characters that preceded it (except the first 100 characters of course). We need to convert the text to integer, as computer understand the only number with one hot coding. The next step would be to check the number of patterns generated. As the training dataset is prepared, the next step would be developing the Keras model. List of sample has been converted into the form [samples, time steps, features] expected by an LSTM network. Rescale the integers to the range 0-to-1 to make the patterns easier to learn by the LSTM network that uses the sigmoid activation function by default. 
The next step would be defining the LSTM model. The hidden LSTM layer with 256 memory units. The network uses dropout with a probability of 20. The output layer is a Dense layer using the softmax activation function to output a probability prediction for each of the 47 characters between 0 and 1. The problem faced is really a single character classification problem with 47 classes and as such is defined as optimizing the log loss (cross entropy), here using the ADAM optimization algorithm for speed. The network is slow to train (about 20 minutes per epoch on NVIDIA GTX 1050). Because of the slowness and because of our optimization requirements, we will use model checkpointing to record all of the network weights to file each time an improvement in loss is observed at the end of the epoch. Which will be used the best set of weights (lowest loss) to instantiate our generative model. I used modest number of 20 epochs and a larger batch size of 128 patterns. The simplest way to use the Keras LSTM model to make predictions is to first start off with a seed sequence as input, generate the next character then update the seed sequence to add the generated character on the end and trim off the first character. This process is repeated for as long as we want to predict new characters (e.g. a sequence of 1,000 characters in length). As the model is trained with the training set as the we have received the weights after the newly generated text has been created with not high accuracy.
Ideas To Improve the Model:
•	Predict fewer than 1,000 characters as output for a given seed.
•	Remove all punctuation from the source text, and therefore from the models’ vocabulary.
•	Try a one hot encoded for the input sequences.
•	Train the model on padded sentences rather than random sequences of characters.
•	Increase the number of training epochs to 100 or many hundreds.
•	Add dropout to the visible input layer and consider tuning the dropout percentage.
•	Tune the batch size; try a batch size of 1 as a (very slow) baseline and larger sizes from there.
•	Add more memory units to the layers and/or more layers.
•	Experiment with scale factors (temperature) when interpreting the prediction probabilities.
•	Change the LSTM layers to be “stateful” to maintain state across batches.

Summary:
In this project, I discovered how to develop an LSTM recurrent neural network for text generation in Python with the Keras deep learning library. Where to download the ASCII text for classical books free that you can use for training. How to train an LSTM network on text sequences and how to use the trained network to generate new sequences. How to develop stacked LSTM networks and lift the performance of the model.

